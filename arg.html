<!DOCTYPE html>
<html lang="en"></html>
<head>
    <meta charset="UTF-8">
    <title>Home</title>
    <link rel='stylesheet' href='style/main.css'>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="author" content="Kenza Filali">
    <meta name="keywords" content="HTML, CSS, XML, XHTML, JavaScript">
</head>

<body>
    <div class="argEssay">
    <header class="essayHeader">
    <ul class="nav"> <!-- This header includes my nav bar that is found in all pages with logo-->
        <a id="pageLogo" href="#top"><img src="media/logo2.png" alt="logo" ></img></a>
        <li><a href="about.html">News</a></li>
        <li><a href="about.html">Podcast</a></li>
        <li><a href="about.html">About Us</a></li>
        <li><a href="about.html">Home</a></li>
    </ul>
    </header>
</body>

    <!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Argumentative Essay: Data Privacy</title>
    
       
</head>
<body>
<div class="argEssayContainer">
  <h1>Argumentative Essay</h1>
  <div class="authors"><strong>Libby Reesor, Liana Manai, Kenza Filali</strong></div>
  <div class="info">
    Mount Royal University<br>
    GNED 1403: Writing in a Digital Context, Language, Media, Culture<br>
    Instructor: Gaby Broitman-Levandovsky<br>
    June 13, 2025
  </div>

    <p>
    <section>
        For over a century, oil has been dominating the market by being the world's most valuable resource, but in recent years data has surpassed that value by a landslide. Unknowingly by many people, this priceless resource is found on the internet, specifically on Social Media. Although we begin to question whether this data is managed ethically due to its immense return on investment, we also wonder the lengths companies are willing to go to for profit. Billions of us give our data away freely, via clicks, cookies and especially social media platforms, but there are severe consequences that result from the public’s lack of knowledge of privacy terms on social media and the laws that accompany them. Due to the lack of due diligence that the general population takes when it comes to online privacy, the door has opened for social media platforms to manipulate and control its users. Social media companies rely on user complacency and the lack of legislation to maximize profits and maintain user retention. This paper examines the ethical implications of social media data, how companies use and profit off our personal data, if users truly provide lawful consent and the psychological consequences on how our data is being used. 
    </p>
    </section>

    <p>
    <section>
        	It appears that our personal data has always been easily accessible and profitable, something we have unknowingly accepted over time. This reality is only evident from microscopic reading, particularly found in the infamously long and tedious “Terms and Conditions” agreements required by nearly every social media platform. Companies purposefully make these texts unapproachable for the reader by hiring typographers to make the language more vague, full of legal jargon and hard to understand. Unfortunately, all social media companies do this to transfer all the liability from them to users, with no repercussions since it is legal to this day. According to the Wall Street Journal, consumers lose $250 billion from what’s hidden in the fine print (Hilsenrath et al., 2008). It is in these agreements, where millions sign off their privacy for unaware monetization and manipulation. That said, implementing regulations for these life-changing contracts is the first step towards protecting our unregulated and unethically used personal data. Moreover, there are companies solely created to collect and use your own personal data against you. For instance, Cambridge Analytica used personal user data to tailor advertisements in favor of political parties (Confessore, 2018). They would collect behavioral analysis via users’ clicks and cookies and categorize a type of user that can be persuaded to vote for their political party of choice (Matara et al., 2024). Cambridge Analytica called these users the “Persuadables”, from there, they would create personalized ads based on their personality to persuade them in their favor (National Public Radio, 2019, 26:53). Acknowledging that lawful consent is not legitimate consent from these terms and conditions and the ethical necessity for our society to have proper and uncorrupted democratic systems. 
    </p>    
    </section>
    
    <p>
    <section>
        Despite the vast magnitude of personal data being used by social media platforms, many users remain uninformed about the practices being made from their contributions. The data that individuals willingly share is utilized in many different aspects that benefit influential corporations while affecting the privacy of users. An equally important concern is the ability of small-scale businesses or companies to access personal information when screening job applicants. The extent of data privacy and security has become an ever growing debate as time progresses.
    </p>    
    </section>
    
    <p>
    <section>
        There have been many governmental attempts to inform citizens over the predatory privacy practices of social media companies, but studies show that informing users may be a difficult task. Regulations in the European Union like the General Data Protection Regulation (GDPR) or the Digital Services Act (DSA) have enforced attempts to notify users on the output of their data usage. One attempt included the addition of a “sponsored” label to targeted ads (Meier et al., 2024). While this policy has been effective in notifying users of persuasion practices (Eisend et al., 2020). It fails to educate users on the personal data being collected in order to generate targeted advertisements (Binder et al., 2022).
    </p>    
    </section>
    
    <p>
    <section>
        More explicit attempts in informing users over the use of their data have shown to be unsuccessful. Strycharz et al. (2019) conducted a study testing whether informing people with knowledge about Google’s data collection and personalization techniques would affect their motivations in regard to privacy. The outcome of the study illustrated that newly learned information of participants did not affect people's sense of privacy threat nor encourage them to opt out from personalized advertisements. The results of these studies convey that users may be aware of the manipulation of personalized ads but simultaneously view benefits or lack concern in sharing their data.
    </p>    
    </section>
    
    <p>
    <section>
        Information shared on social media is also accessible and utilized in job applications and university admissions (George et al., 2014). The information available on social media as opposed to a job resumé may include information that is inappropriate to ask during an assessment process as they are unrelated to the job (Thomas et al., 2014) . While using a candidate’s social media presence may seem harmless, demographic or personal information such as age, gender, race, or political views can be wrongfully used in hiring decisions (Thomas et al., 2014). To combat this, additional legal frameworks have been implemented in the United States and the United Kingdom to regulate the extent in which employers are entitled to some privacy regarding the personal lives of their employees (Jeske & Shultz, 2016). 
    </p>    
    </section>
    
    <p>
    <section>
        On the other hand, employers argue that social media allows the verifiability of information and reveal “hidden or undisclosed truths” (Thomas et al., 2014). Privacy practices from employers may be invasive but also increase an employee's veracity and security screening, overall contributing to a more truthful, safer work environment. Social media screening also allows organizations, especially small scale organizations, to screen many applicants while keeping costs low (Jeske & Shultz, 2016). The extent to which organizations and companies should have access to individuals’ data varies across different legislation as well as personal and public opinions. 
    </p>
    </section>
    
    <p>
    <section>
        While there are beneficial uses, many companies exploit their users without their knowledge. Regardless whether personal data is used by a multi-billion corporation or small scale business, a common practice that is in need is more regulation. Therefore, when breaches of privacy do occur, organizations can be held accountable.
    </p>
    </section>
    
    <p>
    <section>
        A breach in privacy has the ability to cause devastating hardship on its users. By accessing users personal data, they can be manipulated to want certain things that benefit the company and their advertisers. It starts off with something small, maybe an influencer introduces a diet they are using, or you see an ad for a product you use regularly but with an added twist. It continues day after day, until you question whether you need to change yourself to fit a certain standard that you have been exposed to. This is how algorithms work against you and could cost you your self worth. Researchers have not come to clear consensus on what problematic social media use is (Lin et al., 2020, p. 166). As technology has progressed social media companies have used advanced methods to keep users addicted to their platform (Lin et el., 2020, p. 166). By keeping users consistently engaged on their platforms, it can be quite easy to realize just how influential these websites can be. Swart (2020) suggests that recommender algorithms can limit the user’s ability to access accurate or well-rounded information (para. 4). This could be harmful to someone’s mental health if they have trouble disconnecting from what they learn online to the applications of the real world. Vulnerable people who don’t know any better could be consuming content that later gets pushed to their feeds by the algorithm solely because they know (or at least assume) that person will engage with that type of content. One example of how this system could be dangerous was when a Facebook user named Eric Priddle began sharing his recovery journey on the platform. Villani (2025) at CTV News reported that after Eric began sharing his recovery journey from drug use on Facebook, he started to see ads for a suspicious website (Villani, 2025, 00:35). The ads were for pharmaceutical websites that sold substances such as medicinal cocaine and MDMA (Vallani, 2025, 00:47). Priddle (2025) stated that he was concerned about someone in a more vulnerable state seeing these ads and whether they would want to report them (01:06). Big companies such as Meta, systems are automated and it would just take someone who knows how the systems work to get their illegal ad posted and pushed by the algorithm. This can harm vulnerable individuals who are posting and interacting with content without being aware of how it could affect their mental health. Algorithms have the power to manipulate the public and open the possibility for devastating consequences on our mental health.
    </p>
    </section>
    
    <p>
    <section>
        With the continuous development of recommender algorithms, there is also growing concern around data privacy and what the future holds for social media users. As stated above, there are devastating consequences to how data collected from social media profiles is used. It is especially important for social media users to not only understand how our data is being used now but also learn what is in store for the future. Social media data is used by marketers to gain a further understanding of opinions of certain demographics, to learn how to relate to their customers better and strategically target ads to consumers who are most likely to purchase from them (Jacobson et al., 2020, para. 8). Although these practices are common in today’s day in age, there are still growing privacy concerns among social media users (Jacobson et al., (2020), para. 12). Cases that involve privacy concerns against social media companies grow more common as time goes on (Bleier et al., 2020, para. 20). However, we have to wonder if legal action taken against these companies is enough. Cloarec, Meyer-Waarden and Munzel (2024) suggested that there is a privacy and personalization paradox that indicates a love-hate relationship between recommender algorithms and growing privacy concerns (para. 2). Collecting and using our data seemed to happen without much concern coming from users. However, as research further investigates data privacy and what our information is being used for it raises the concern about our data being used ethically. With the increase in concern from social media users, companies will be forced to develop solutions to ensure the safety and privacy of its users or face extreme consequences.
    </p>
    </section>

     <section>
      <p>
        Data privacy becomes more complicated as time progresses due to more users sharing their information with technological advances. Legislation's ability to enforce safety measures and protect users from exploitation has become a growing concern as social media companies continue to profit off their vast power over data. Government regulation that promotes user privacy will not only prevent a monopoly holding a majority of the data but also improve the well being of citizens who choose to participate in social media sites. The protection of privacy will include limits on targeted ads, especially ones that have been observed in the past to hold democratic processes in jeopardy. Additionally, privacy protection will make hiring processes more reasonable and inclusive. Since data can include many pieces of sensitive information, the opportunities of exploitation from social media companies or third parties has been exhausted and invasive towards all its users. Current legislation is not only needed now but also required to adapt quickly in order to keep up with growth of technology. With new advancements such as artificial intelligence, privacy has never been more important.
      </p>
    </section>
</div>
    <footer>
    <h2>Works Cited</h2>
    <img src="media/ref1.png" width="100%">
    <img src="media/ref2.png" width="100%">
    <img src="media/ref3.png" width="100%">
    
  </footer>
    </div>
</body>
</html>

</div>